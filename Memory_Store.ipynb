{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9d74246b-e8b1-4400-acae-4de8500aeb82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet sagemaker\n",
    "!pip install langchain --quiet\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef6f58-1bac-41e8-95f3-691ec81ada10",
   "metadata": {},
   "source": [
    "å®šä¹‰ContentHandlerä»¥æ ‡å‡†åŒ–Sagemaker Endpointçš„è¾“å…¥å’Œè¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9c337376-3953-4e0f-920b-98dd344caf88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "        payload = {\n",
    "            \"inputs\": [[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]],\n",
    "        }\n",
    "        \n",
    "        input_str = json.dumps(payload)\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes):\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return (f\"> {response_json[0]['generation']['role'].capitalize()}: {response_json[0]['generation']['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82660639-a84d-4c3a-99f2-5aee21f0d605",
   "metadata": {},
   "source": [
    "å®žä¾‹åŒ–Endpoint LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d2f35bf9-a9dc-4ebd-9698-6d09330852cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_handler = ContentHandler()\n",
    "\n",
    "llm=SagemakerEndpoint(\n",
    "        endpoint_name=\"meta-textgeneration-llama-2-13b-f-2023-07-30-08-44-18-636\",\n",
    "        region_name=\"us-east-1\",\n",
    "        #model_kwargs={\"max_new_tokens\": 512, \"top_p\": 0.9, \"temperature\": 0.6},\n",
    "        content_handler=content_handler,\n",
    "        model_kwargs=parameters,\n",
    "        endpoint_kwargs = {\"CustomAttributes\": \"accept_eula=true\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388458d-56b4-479d-916a-34cf561364d3",
   "metadata": {},
   "source": [
    "## æ²¡æœ‰åŠ å…¥Memoryä¹‹å‰ï¼Œç”¨llm chainæµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3b2c2cc6-3f62-429a-97ad-b98483f7d8ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"ä½ æ˜¯ä¸€ä¸ªèŠå¤©æœºå™¨äºº.\n",
    "\n",
    "Human: {human_input}\n",
    "AI:\"\"\"\n",
    " \n",
    "    \n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "12174016-e733-4554-8622-e31441df1078",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"> Assistant:  Hello Sean! My name is LLaMA, I'm a chatbot developed by Meta AI. It's nice to meet you! ðŸ˜Š What can I help you with today? Please keep in mind that I'm here to assist you in a respectful, honest, and safe manner. If your question doesn't make sense or is not factually coherent, I'll do my best to explain why instead of providing an incorrect answer. Let's get started! ðŸ’¡\""
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"Hi, my name is Sean, and you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0c562379-ff97-4d3b-8fb6-89407488efb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"> Assistant:  Hello! I'm here to assist you in a helpful, respectful, and honest manner. I'm a safe and knowledgeable AI assistant, and I'm here to provide information and answer your questions to the best of my ability. However, I cannot remember personal information such as names, as I'm a text-based AI and do not have the ability to store or recall personal data. If you'd like to introduce yourself, I'd be happy to chat with you and assist you with any questions you may have!\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"so, do you remember my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c6a7b-e56a-4a50-b562-2da1e3b35504",
   "metadata": {},
   "source": [
    "## åŠ å…¥Memoryä¹‹åŽï¼Œç”¨llm chainæµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2746eb71-3d05-4fa3-a21c-323fa302d430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"ä½ æ˜¯ä¸€ä¸ªèŠå¤©æœºå™¨äºº.\n",
    " \n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "AI:\"\"\"\n",
    " \n",
    "    \n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6d43c528-b1ad-4e2a-a431-ba8070ac01b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "53de0964-b5f8-4a18-83f2-41afbb59ceac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mä½ æ˜¯ä¸€ä¸ªèŠå¤©æœºå™¨äºº.\n",
      " \n",
      "\n",
      "Human: Hi, my name is Sean, and you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"> Assistant:  Hello Sean! My name is Assistant, and it's nice to meet you. I'm here to help answer any questions you may have. Please keep in mind that I am a safe and respectful assistant, and I will not provide any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. I strive to provide socially unbiased and positive responses. If a question does not make sense or is not factually coherent, I will explain why instead of providing an incorrect answer. If I don't know the answer to a question, I will not provide false information. Please feel free to ask me anything!\""
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"Hi, my name is Sean, and you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "af1abf37-78b5-40c0-b435-b6ff8acacf98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mä½ æ˜¯ä¸€ä¸ªèŠå¤©æœºå™¨äºº.\n",
      " \n",
      "Human: Hi, my name is Sean, and you?\n",
      "AI: > Assistant:  Hello Sean! My name is Assistant, and it's nice to meet you. I'm here to help answer any questions you may have. Please keep in mind that I am a safe and respectful assistant, and I will not provide any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. I strive to provide socially unbiased and positive responses. If a question does not make sense or is not factually coherent, I will explain why instead of providing an incorrect answer. If I don't know the answer to a question, I will not provide false information. Please feel free to ask me anything!\n",
      "Human: so, do you remember my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"> Assistant:  Assistant: Hello Sean! Yes, I remember your name. You introduced yourself as Sean when you first asked me a question. Please let me know if there's anything else you'd like to know or discuss!\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"so, do you remember my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e646f-3aca-43c2-bb74-2337eba50010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
